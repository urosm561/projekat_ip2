Neural network results

Seed: 561

Validation leaderboard
 n1  n2  n3  p_drop  max_aa_length resample_strategy  accuracy  precision   recall       f1
256 128  32     0.1              6              None  0.907360   0.919854 0.907360 0.912666
256  64  32     0.1              6              None  0.905038   0.922003 0.905038 0.912417
128  64  64     0.1              7              over  0.908869   0.923769 0.908869 0.911891
256 128  64     0.1              7              over  0.900046   0.923864 0.900046 0.908239
128 128  64     0.1              6              over  0.893894   0.921925 0.893894 0.906308
256  64  32     0.1              5              None  0.896215   0.917745 0.896215 0.905698
256  64  64     0.1              6              over  0.895867   0.917080 0.895867 0.904780
128  64  32     0.1              5              over  0.893429   0.917396 0.893429 0.904025
128  64  64     0.1              6              None  0.892268   0.915697 0.892268 0.902563
128  64  32     0.1              6              over  0.887741   0.923842 0.887741 0.902520
128 128  64     0.1              7              over  0.888205   0.915591 0.888205 0.900180
128  64  64     0.1              6              over  0.887160   0.916562 0.887160 0.899530
256  64  32     0.1              7              None  0.886464   0.917133 0.886464 0.899474
256 128  32     0.1              5              over  0.881588   0.921405 0.881588 0.898700
128 128  64     0.1              7              None  0.885187   0.916182 0.885187 0.898542
256  64  64     0.1              5              None  0.881820   0.919437 0.881820 0.898121
256  64  64     0.1              5              over  0.882749   0.917674 0.882749 0.897346
128 128  32     0.1              6              over  0.884026   0.915668 0.884026 0.897273
128 128  32     0.1              7              over  0.886580   0.913063 0.886580 0.897233
128  64  32     0.1              7              None  0.881588   0.918543 0.881588 0.897051
256  64  32     0.1              5              over  0.884839   0.915892 0.884839 0.897050
256  64  64     0.1              6              None  0.878918   0.919109 0.878918 0.895770
256 128  64     0.1              6              None  0.880543   0.916187 0.880543 0.895040
256  64  64     0.1              7              None  0.880195   0.914708 0.880195 0.894808
256  64  32     0.1              7              over  0.875203   0.919345 0.875203 0.894163
128 128  32     0.1              6              None  0.878570   0.915121 0.878570 0.893862
128 128  64     0.1              5              None  0.876596   0.915246 0.876596 0.893015
256 128  32     0.1              7              over  0.879034   0.914515 0.879034 0.892469
128 128  64     0.1              5              over  0.874623   0.916377 0.874623 0.892320
256 128  32     0.1              7              None  0.874274   0.916109 0.874274 0.892063
128  64  32     0.1              6              None  0.876364   0.912228 0.876364 0.891121
128  64  32     0.1              5              None  0.872997   0.914729 0.872997 0.890310
256  64  32     0.1              6              over  0.871720   0.913530 0.871720 0.889116
256 128  32     0.1              5              None  0.869283   0.915510 0.869283 0.888986
256 128  32     0.1              6              over  0.864755   0.918586 0.864755 0.887586
128  64  32     0.1              7              over  0.868354   0.913381 0.868354 0.887332
256 128  64     0.1              7              None  0.868238   0.912460 0.868238 0.885801
128 128  64     0.1              6              None  0.862201   0.917670 0.862201 0.885294
256 128  64     0.1              5              over  0.863130   0.914672 0.863130 0.884011
256 128  64     0.1              5              None  0.860692   0.918515 0.860692 0.883934
128 128  32     0.1              5              None  0.859995   0.919584 0.859995 0.883452
128  64  64     0.1              5              None  0.860344   0.910948 0.860344 0.881787
256 128  64     0.1              6              over  0.846529   0.919662 0.846529 0.874888
128  64  64     0.1              5              over  0.840608   0.916683 0.840608 0.871800
256  64  64     0.1              7              over  0.834920   0.916030 0.834920 0.867692
128 128  32     0.1              5              over  0.825981   0.924185 0.825981 0.866550
128 128  32     0.1              7              None  0.830973   0.912864 0.830973 0.864327
128  64  64     0.1              7              None  0.825517   0.908604 0.825517 0.859651

Best parameters
n1                   256.0
n2                   128.0
n3                    32.0
p_drop                 0.1
max_aa_length          6.0
resample_strategy      NaN

Model metrics on the test set
accuracy  : 0.8815881123752032
precision : 0.9155441835848979
recall    : 0.8815881123752032
f1        : 0.8956105379491875

Confusion matrix
 1222     0    69    43
    7    36     4    98
   96    71  2488    89
    6    25     2    51

Model metrics on the train set
accuracy  : 0.8889548233958564
precision : 0.9201833661748003
recall    : 0.8889548233958564
f1        : 0.9011581506607849

Confusion matrix
10999     8   588   412
   96   410    49   754
  808   611 22485   786
   57   110    25   561
